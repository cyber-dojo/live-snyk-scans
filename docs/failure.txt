
At present the snyk-container-test calls are running ok
for some Artifacts, but failing for others.

OK:
- custom-start-points
- exercise-start-points
- languages-start-points
- creator 
 
FAILING:
- dashboard
- differ
- nginx
- runner
- saver
- web 

So it appears that recently built Artifacts from github workflows are for
some reason failing the snyk scan.
Does this correspond to the message I saw in the -debug log, which seemed to 
indicate there were no layers in the image?
Viz. See https://github.com/cyber-dojo/saver/actions/runs/22022326417/job/63633428069#step:7:136
  2026-02-14T18:38:49Z legacycli:1 - snyk Error getting layers and manifest content from 
  docker archive: We found no layers in the provided image

For saver [docker image ls] I get this:
  IMAGE                   ID             DISK USAGE   CONTENT SIZE   EXTRA
  2445.../saver:cb348b6   7fc5e4914297        346MB             0B        

For custom-start-points [docker image ls] I get this:
  IMAGE                                 ID             DISK USAGE   CONTENT SIZE   EXTRA
  2445.../custom-start-points:b357983   fd6fcb6d209f        328MB             0B        

So it would seem not.


For custom-start-points, the scan is this:
      - name: Run Snyk container scan
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        run: |
          docker image ls
          snyk container test ${IMAGE_NAME} \
            --policy-path=.snyk \
            --sarif \
            --sarif-file-output="${SARIF_FILENAME}"

For saver, the scan is this:
      - name: Run Snyk container scan
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        run: |
          docker image ls
          make snyk-container-scan

So it is the same token.

============================================================================
Conclusion: Is it something to do with the way the image is built?
Or saved/uploaded/retrieved from caches?

For custom-start-points:

      - name: Build image (directly)
      - name: Configure AWS credentials
      - name: Login to Amazon ECR
      - name: Push image to registry and make digest available
      - name: Set image cache outputs
      - name: Save image
        run:
          docker image save ${{ env.CACHE_KEY }} --output ${{ env.CACHE_PATH }}

      - name: Cache image
        uses: actions/cache@v4
        with:
          path: ${{ env.CACHE_PATH }}
          key:  ${{ env.CACHE_KEY }}

And then, in snyk-container-scan job:

      - name: Retrieve Docker image from cache
        uses: actions/cache@v4
        with:
          key:  ${{ env.CACHE_KEY }}
          path: ${{ env.CACHE_PATH }}

      - name: Load Docker image
        run:
          docker image load --input "${{ env.CACHE_PATH }}"


For saver it is:

  build-image:
    needs: [setup]
    uses: cyber-dojo/reusable-actions-workflows/.github/workflows/secure-docker-build.yml@main
    with:
      ...

followed by this in the snyk-container-scan job:

      - name: Download docker image
        uses: cyber-dojo/download-artifact@main
        with:
          image_digest: ${{ needs.build-image.outputs.digest }}

What does secure-docker-build.yml do?

      - name: Configure AWS credentials
      - name: Login to Amazon ECR
      - uses: actions/checkout@v4
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push Docker image to Amazon ECR
        uses: docker/build-push-action@v6
        with:
          context: .
          no-cache: true
          push: true
          tags: ${{ inputs.image_name }}:${{ inputs.image_tag }}
          build-args: ${{ inputs.image_build_args }}
          provenance: mode=max
          sbom: true
      ...
      - name: Save Docker image ready to upload
        run: |          
          docker pull ${{ inputs.image_name }}:${{ inputs.image_tag }}
          docker image save ${{ inputs.image_name }}:${{ inputs.image_tag }} --output ${{ runner.temp }}/${{ env.DIGEST }}.tar

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.DIGEST }}
          path: ${{ runner.temp }}/${{ env.DIGEST }}.tar

...and then... (in download-artifact)

    - name: Download artifact
      uses: actions/download-artifact@v4
      with:
        name: ${{ inputs.image_digest }}
        path: ${{ runner.temp }}

    - name: Load image
      shell: bash
      run:
        docker load --input ${{ runner.temp }}/${{ inputs.image_digest }}.tar

So, summary

- CSP does build directly, saver uses buildx
- CSP does build,config,login, saver does configure,login,build 
- CSP does not do a [docker pull], saver does
- CSP uses actions/cache, saver uses actions/upload|download-artifact

What does Kosli server do?

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4

      - name: Set up Docker Buildx (buildkit) runner
        uses: docker/setup-buildx-action@v3.0.0

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push Docker image to ECR
        id: docker_build
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: '${{ env.IMAGE_TAGS }}'
          cache-from: type=registry,ref=${{ env.TAGGED_IMAGE_PREVIOUS }}
          cache-to: type=inline,mode=max
          build-args: |
            COMMIT_SHA=${{ github.sha }}
          # By default, we use docker layer cache for faster builds.
          # To force full rebuild we use `no-cache: true`. This is to make sure everything is up-to-date
          # Snyk scanning sometimes needs this
          no-cache: true

      - name: Save server Docker image to cache for the following jobs
        run: |
          docker pull ${{ env.TAGGED_IMAGE }}
          docker image save ${{ env.TAGGED_IMAGE }} --output /tmp/kosli:${{ github.sha }}.tar

      - name: Cache server Docker image
        uses: actions/cache@v4
        with:
          path: /tmp/kosli:${{ github.sha }}.tar
          key: ${{ env.TAGGED_IMAGE }}

...and then...

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4

    - name: Login to Amazon ECR
      uses: aws-actions/amazon-ecr-login@v2

    - name: Pull server Docker image
      shell: bash
      run: docker pull ${{ inputs.tagged_image }}

    - name: Create image tag for $IMAGE as set in Makefile so we don't rebuild the image
      shell: bash
      run: docker tag ${{ inputs.tagged_image }} merkely

So it doesn't use a cache or an download.
It does a direct docker push/docker pull
Which is what I do in the live-snyk-scan workflow!?
